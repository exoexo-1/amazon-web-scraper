# Web Scraping Mini Project - Amazon Product Data Extraction

This mini project demonstrates web scraping using **Selenium** and **BeautifulSoup** to extract product data from Amazon. It collects details like the title, price, and product link from Amazon search result pages and stores them into HTML files. The extracted data is then processed and stored in a CSV file.

## Project Overview

The project consists of three main scripts:
1. **fetching_query.py**: Automates the process of navigating Amazon search result pages, extracting product details, and saving them as HTML files.
2. **locating_multiple.py**: Extracts and prints the details of products from multiple pages.
3. **collect_csv.py**: Parses the HTML files generated by `fetching_query.py` and extracts data to store in a CSV file.

## Features
- Scrapes product information such as:
  - Product Title
  - Price
  - Product Link
- Saves scraped data in an organized format (HTML files per product).
- Converts scraped data into a structured CSV file for further analysis.

## Requirements

Before running this project, make sure you have the following libraries installed:

- Python 3.x
- `selenium`
- `beautifulsoup4`
- `pandas`
- `chromedriver` (can be installed via `webdriver-manager`)

### Install Dependencies

To install the required libraries, run:

```bash
pip install selenium beautifulsoup4 pandas webdriver-manager

How to Use
Step 1: Fetch Amazon Product Data
Run the fetching_query.py script to extract data from Amazon for a specific query (e.g., "laptop"). The script will automatically navigate through pages and save HTML files.

python fetching_query.py

Step 2: Parse HTML Files and Store Data in CSV
After collecting HTML files, use the collect_csv.py script to parse the files and convert the data into a CSV file.


python collect_csv.py
This will generate a CSV file named data.csv with the extracted product data.

Step 3: Locate and Extract Product Data
Use locating_multiple.py to extract and display product data directly from Amazon pages.


python locating_multiple.py
Files in the Project
fetching_query.py: Scrapes Amazon pages for a given query and stores data in HTML files.
locating_multiple.py: Extracts and prints product data directly from Amazon search results.
collect_csv.py: Converts HTML files into a CSV format containing product title, price, and links.
Output
HTML Files: Generated for each product on Amazon for the search query.
CSV File: data.csv containing the extracted product data.
Example Output
Title: "Laptop XYZ"
Price: "$599.99"
Link: Product Link
Notes
The script is designed to work with Amazon's search results pages. It currently only handles pages for a search query.
Make sure to adjust the query parameter in the fetching_query.py script to search for other products.
Always respect website scraping policies and terms of service when scraping data.
License
This project is open-source and available under the MIT License.



### How to Add This to Your GitHub Repository:
1. **Create a New Repository** on GitHub.
2. **Clone the Repository** to your local machine:
   ```bash
   git clone https://github.com/yourusername/repository-name.git
Navigate to your project folder and create a new file called README.md.
Copy and Paste the above content into the README.md file.
Commit and Push the changes to GitHub:

git add README.md
git commit -m "Add README"
git push origin main
